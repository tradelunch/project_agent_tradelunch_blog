#!/usr/bin/env python
# 91_test_improved_agents.py
"""
91. Improved Agent Tests - ê°œì„ ëœ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸

ê°œì„ ëœ ê¸°ëŠ¥ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
- DocumentScannerAgent - í´ë” êµ¬ì¡° ìŠ¤ìº”
- ê°œì„ ëœ ExtractingAgent - íƒœê·¸/ìš”ì•½ ìƒì„±
- ê°œì„ ëœ UploadingAgent - ì¸ë„¤ì¼ ìš°ì„  ì²˜ë¦¬
- ìŠ¤í‚¤ë§ˆ ê²€ì¦

í…ŒìŠ¤íŠ¸ ìˆœì„œ:
1. DocumentScanner - í´ë” ìŠ¤ìº”
2. Improved Extracting - ë©”íƒ€ë°ì´í„° ìƒì„±
3. Improved Uploading - ì¸ë„¤ì¼ ì²˜ë¦¬
4. Schema - ìŠ¤í‚¤ë§ˆ ì„¤ëª… ìƒì„±
5. LLM Integration - Qwen3 í†µí•© (ì˜µì…˜)
"""

import asyncio
from agents import DocumentScannerAgent, ExtractingAgent, UploadingAgent, AgentTask
from schema import PostSchema, PostWithRelations, get_schema_description, generate_slug_from_title


async def test_document_scanner():
    """DocumentScannerAgent í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("Testing DocumentScannerAgent")
    print("=" * 60)

    scanner = DocumentScannerAgent()

    task = AgentTask.create(action="scan", data={"root_path": "./docs"})

    result = await scanner.run(task.to_dict())

    if result["success"]:
        data = result["data"]
        print(f"âœ… Found {data['total_articles']} articles")
        print(f"âœ… Categories: {data['total_categories']}")

        print("\nCategory Tree:")
        print(scanner.get_category_summary(data["category_tree"]))

        print("\nArticles:")
        for article in data["articles"]:
            print(f"  ğŸ“„ {article['article_name']}")
            # Show full category hierarchy
            categories = article.get('categories', [])
            if categories:
                category_path = ' > '.join(categories)
                print(f"     Categories: {category_path}")
            else:
                print(f"     Categories: (root)")
            print(f"     Thumbnail: {'âœ“' if article['thumbnail'] else 'âœ—'}")
            print(f"     Images: {len(article['images'])}")

        return result
    else:
        print(f"âŒ Failed: {result.get('error')}")
        return None


async def test_improved_extracting(article_info):
    """ê°œì„ ëœ ExtractingAgent í…ŒìŠ¤íŠ¸ (íƒœê·¸ì™€ ìš”ì•½ ìƒì„±)"""
    print("\n" + "=" * 60)
    print("Testing Improved ExtractingAgent")
    print("=" * 60)

    # Test without LLM first (basic functionality)
    # LLM is now auto-enabled by default, so explicitly disable for basic test
    agent = ExtractingAgent(enable_llm=False)

    task = AgentTask.create(
        action="extract",
        data={"article_info": article_info, "extract_metadata": False},
    )

    result = await agent.run(task.to_dict())

    if result["success"]:
        data = result["data"]
        print(f"âœ… Title: {data['title']}")
        print(f"âœ… Slug: {data['slug']}")
        # Show full category hierarchy
        categories = data.get('categories', [])
        if categories:
            category_path = ' > '.join(categories)
            print(f"âœ… Categories: {category_path}")
        else:
            print(f"âœ… Categories: (root)")
        print(f"âœ… Word count: {data['word_count']}")
        print(f"âœ… Reading time: {data['reading_time']} min")
        print(f"âœ… Images: {len(data.get('images', []))}")
        if data.get("thumbnail"):
            print(f"âœ… Thumbnail: {data['thumbnail']['local_path']}")

        # ìŠ¤í‚¤ë§ˆ í˜¸í™˜ì„± ì²´í¬
        try:
            # Create PostSchema from extracted data
            post_data = {
                "user_id": 1,  # Default test user
                "slug": data.get("slug", generate_slug_from_title(data['title'])),
                "title": data.get("title"),
                "description": data.get("summary", ""),
                "content": data.get("content"),
                "status": "public",
            }

            post = PostSchema(**post_data)
            print("\nâœ… Schema validation passed!")
            print(f"   Post schema fields: {len(post.model_fields)}")
            print(f"   Slug: {post.slug}")
        except Exception as e:
            print(f"\nâš ï¸  Schema validation failed: {e}")

        return result
    else:
        print(f"âŒ Failed: {result.get('error')}")
        return None


async def test_improved_uploading(extracted_data):
    """ê°œì„ ëœ UploadingAgent í…ŒìŠ¤íŠ¸ (ì¸ë„¤ì¼ ìš°ì„ )"""
    print("\n" + "=" * 60)
    print("Testing Improved UploadingAgent")
    print("=" * 60)

    agent = UploadingAgent()

    task = AgentTask.create(action="full_upload", data=extracted_data["data"])

    result = await agent.run(task.to_dict())

    if result["success"]:
        data = result["data"]
        print(f"âœ… Article ID: {data['article_id']}")
        print(f"âœ… Published URL: {data['published_url']}")
        if data.get("thumbnail_url"):
            print(f"âœ… Thumbnail URL: {data['thumbnail_url']}")
        print(f"âœ… Images uploaded: {data['image_count']}")

        return result
    else:
        print(f"âŒ Failed: {result.get('error')}")
        return None


async def test_schema_description():
    """ìŠ¤í‚¤ë§ˆ ì„¤ëª… ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("Testing Schema Description")
    print("=" * 60)

    schema_desc = get_schema_description(PostSchema)

    print("Schema fields that LLM should extract:")
    print(schema_desc)

    print("\nâœ… Schema description generated")
    print(f"   Total fields: {len(PostSchema.model_fields)}")


async def test_with_llm():
    """LLMì„ ì‚¬ìš©í•œ ì „ì²´ í…ŒìŠ¤íŠ¸ (local/openai/anthropic)"""
    print("\n" + "=" * 60)
    print("Testing with LLM (Auto-configured from config.LLM_PROVIDER)")
    print("=" * 60)

    try:
        from llm_factory import create_llm, get_provider_info

        # Show current LLM configuration
        info = get_provider_info()
        print(f"Provider: {info['provider']}")
        print(f"Model: {info.get('model', 'N/A')}")
        print(f"Available: {info.get('available', True)}")

        # Scannerë¡œ article ì°¾ê¸°
        scanner = DocumentScannerAgent()
        scan_result = await scanner.run(
            AgentTask.create(action="scan", data={"root_path": "./docs"}).to_dict()
        )

        if not scan_result["success"] or not scan_result["data"]["articles"]:
            print("âš ï¸  No articles found")
            return False

        article_info = scan_result["data"]["articles"][0]

        # ExtractingAgent with auto-configured LLM
        # It will auto-create LLM from config.LLM_PROVIDER
        agent = ExtractingAgent()  # enable_llm=True by default
        result = await agent.run(
            AgentTask.create(
                action="extract",
                data={
                    "article_info": article_info,
                    "extract_metadata": True,
                },
            ).to_dict()
        )

        if result["success"]:
            data = result["data"]
            print(f"\nâœ… Generated Metadata:")
            print(f"   Tags: {', '.join(data.get('tags', []))}")
            print(f"   Summary: {data.get('summary', 'N/A')[:100]}...")
            return True
        else:
            print(f"âŒ Failed: {result.get('error')}")
            return False

    except Exception as e:
        print(f"âš ï¸  LLM test failed: {e}")
        print("    Troubleshooting:")
        print("    - Local: Make sure Ollama is running (ollama serve)")
        print("    - OpenAI: Check OPENAI_API_KEY is set")
        print("    - Anthropic: Check ANTHROPIC_API_KEY is set")
        print("    See LLM_SETUP.md for detailed configuration")
        return False


async def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ğŸ§ª Improved Multi-Agent System - Test Suite")
    print("=" * 60)

    results = {}

    # Phase 1: DocumentScanner
    scan_result = await test_document_scanner()
    results["scanner"] = scan_result is not None

    if scan_result and scan_result["data"]["articles"]:
        # ì²« ë²ˆì§¸ articleë¡œ í…ŒìŠ¤íŠ¸
        article_info = scan_result["data"]["articles"][0]

        # Phase 2: Improved Extracting
        extract_result = await test_improved_extracting(article_info)
        results["extracting"] = extract_result is not None

        if extract_result:
            # Phase 3: Improved Uploading
            upload_result = await test_improved_uploading(extract_result)
            results["uploading"] = upload_result is not None

    # Phase 4: Schema
    await test_schema_description()
    results["schema"] = True

    # Phase 5: LLM (Optional)
    user_input = input("\nTest with LLM (uses config.LLM_PROVIDER)? (y/n): ").lower()
    if user_input == "y":
        results["llm"] = await test_with_llm()
    else:
        print("â­ï¸  Skipping LLM test")
        print("    To test LLM: python test_llm_providers.py")
        results["llm"] = None

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š Test Results Summary")
    print("=" * 60)

    for name, passed in results.items():
        if passed is None:
            status = "â­ï¸  SKIPPED"
        elif passed:
            status = "âœ… PASSED"
        else:
            status = "âŒ FAILED"

        print(f"{status} - {name.replace('_', ' ').title()}")

    passed_count = sum(1 for p in results.values() if p is True)
    total_count = sum(1 for p in results.values() if p is not None)

    print()
    print(f"Total: {passed_count}/{total_count} tests passed")
    print("=" * 60)

    if passed_count == total_count and total_count > 0:
        print("\nğŸ‰ All tests passed! Improved system is ready.")
        print("\nNew Features:")
        print("  âœ… Folder structure scanning")
        print("  âœ… Category from path extraction")
        print("  âœ… Thumbnail detection")
        print("  âœ… Reading time calculation")
        print("  âœ… Schema validation")
        print("  âœ… LLM-powered tags & summary generation")
    else:
        print("\nâš ï¸  Some tests failed. Please check the errors above.")


if __name__ == "__main__":
    asyncio.run(main())
